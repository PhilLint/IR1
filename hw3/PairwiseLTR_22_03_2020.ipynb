{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PairwiseLTR_22-03-2020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GhNC8yFuD2eo",
        "outputId": "aef36a4d-302c-4aa2-e7d7-0f474ccc6378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "% cd drive/My Drive/hw3/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'drive/My Drive/hw3/'\n",
            "/content/drive/My Drive/hw3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gAbI82HvEJgL",
        "colab": {}
      },
      "source": [
        "import dataset\n",
        "import ranking as rnk\n",
        "import evaluate as evl\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "import itertools\n",
        "\n",
        "import math\n",
        "data = dataset.get_dataset().get_data_folds()[0]\n",
        "data.read_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ILMI8Kmhakp5",
        "colab": {}
      },
      "source": [
        "\n",
        "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#torch.manual_seed(0)\n",
        "\n",
        "class RankNet(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden):\n",
        "        super(RankNet, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
        "        self.output = torch.nn.Linear(n_hidden, 1)      \n",
        "        \n",
        "    def forward(self, x1):\n",
        "        x = torch.nn.functional.relu(self.hidden(x1))\n",
        "        x = self.output(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Model():\n",
        "    def __init__(self, n_feature, n_hidden, learning_rate, sigma):\n",
        "        self.ranknet = RankNet(n_feature, n_hidden)\n",
        "        #.to(device)\n",
        "        self.optimizer = torch.optim.SGD(self.ranknet.parameters(), lr=learning_rate)\n",
        "\n",
        "def eval_model(model, data_fold):\n",
        "    #with torch.no_grad():\n",
        "        x = torch.from_numpy(data_fold.feature_matrix).float()\n",
        "        y = data_fold.label_vector\n",
        "        model.ranknet.eval()\n",
        "               \n",
        "        output = model.ranknet(x)\n",
        "        output = output.detach().cpu().numpy().squeeze()\n",
        "        \n",
        "        scores = evl.evaluate(data_fold, np.asarray(output))  \n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    # data = dataset.get_dataset().get_data_folds()[0]\n",
        "    # data.read_data()\n",
        "\n",
        "    train_x = torch.from_numpy(data.train.feature_matrix).float()\n",
        "    train_y = torch.from_numpy(data.train.label_vector).float()\n",
        "\n",
        "    # documents = data.train.feature_matrix\n",
        "    # doc_list = list(range(len(documents)))\n",
        "    \n",
        "    # # Carthesian product\n",
        "    # Carth = list(itertools.combinations(doc_list,2))\n",
        "    # x1, x2, target = [], [], []\n",
        "  \n",
        "    # # iterate over all possible combinations\n",
        "    # for i,j in Carth:\n",
        "    #     x1.append(docs[i])\n",
        "    #     x2.append(docs[j])\n",
        "    #     if data.train.label_vector[i]>data.train.label_vector[j]:\n",
        "    #         # this is the S_{ij}\n",
        "    #         target.append(float(1))\n",
        "    #     elif data.train.label_vector[i]<data.train.label_vector[j]:\n",
        "    #         target.append(float(-1))\n",
        "    #     else:\n",
        "    #         target.append(float(0))\n",
        "\n",
        "\n",
        "    train_set = TensorDataset(train_x, train_y)\n",
        "    train_loader = DataLoader(dataset=train_set, batch_size=32, shuffle=True)\n",
        "#     return torch.FloatTensor(x1), torch.FloatTensor(x2), torch.FloatTensor(target)\n",
        "    #return data\n",
        "    return train_loader\n",
        "       \n",
        "\n",
        "def plot_ndcg_loss(ndcgs):\n",
        "    x = np.arange(len(ndcgs))\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    ax.plot(x, ndcgs, label='NDCG')\n",
        "    ax.set_xlabel(\"Batch % 2000\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_title(\"Pairwise LTR\")\n",
        "    legend = ax.legend(loc='upper center')\n",
        "    \n",
        "    plt.show()\n",
        "    plt.savefig('Pairwise_LTR_plot.png')\n",
        "\n",
        "    \n",
        "def train_batch(documentfeatures, labels, model, sig):\n",
        "#     model.ranknet.train()\n",
        "    for epoch in range(1):\n",
        "#         for qid in range(0, train_data.num_queries()):\n",
        "#             if train_data.query_size(qid) < 2:\n",
        "#                 continue\n",
        " \n",
        "            model.optimizer.zero_grad()\n",
        "\n",
        "            output = model.ranknet(documentfeatures)\n",
        "            \n",
        "            loss = pairwiseloss(output, labels, sig)\n",
        "        \n",
        "            loss.backward()\n",
        "            \n",
        "            model.optimizer.step()\n",
        "            \n",
        "    return model\n",
        "    \n",
        "def pairwiseloss(predictedvals, values, sig):\n",
        "    \n",
        "    predictedvals = predictedvals.squeeze()\n",
        "\n",
        "    # Hier is waar er is gesleuteld aan de data om de nan's te voorkomen\n",
        "    if values.shape[0] == 1:\n",
        "        return (predictedvals - values)**2\n",
        "    # pairs = int(math.factorial(n_docs) / (math.factorial(n_docs - 2) * 2))\n",
        "    pairs = list(itertools.combinations(range(predictedvals.shape[0]), 2))\n",
        "    val1, val2 = [x[0] for x in pairs], [x[1] for x in pairs]\n",
        "    #todevice\n",
        "    # pred1 = predictedvals[val1]\n",
        "    # pred2 = predictedvals[val2]\n",
        "    \n",
        "    # true1 = values[val1]\n",
        "    # true2 = values[val2]\n",
        "    # #.todevice\n",
        "    # s1 = (true1 > true2).type(torch.FloatTensor)\n",
        "    # s2 = (true1 < true2).type(torch.FloatTensor)\n",
        "    \n",
        "    # S =  s1 - s2\n",
        "    # pairs = list(itertools.combinations(range(preds.shape[0]), 2))\n",
        "    # idx1, idx2 = [pair[0] for pair in pairs], [pair[1] for pair in pairs]\n",
        "   \n",
        "    S = torch.sign(values[val1] - values[val2])\n",
        "    s = predictedvals[val1] - predictedvals[val2]   \n",
        "        \n",
        "    C_T = 0.5 * (1 - S) * sigma * s + torch.log(1 + torch.exp(-sigma * s))\n",
        " \n",
        "    return C.sum()    sigma = sig * (pred1 - pred2)\n",
        "    # C_T = (0.5 * (1 - S) * sigma + torch.log(1 + torch.exp(-sigma)))\n",
        "    # C_T = torch.tensor(C_T, requires_grad = True)\n",
        "    \n",
        "    # return C_T.mean()\n",
        "    return C_T.sum()\n",
        "\n",
        "\n",
        "def hyperparam_search():\n",
        "    # hyper-parameters\n",
        "    epochs = 10\n",
        "    learning_rates = [10**-1, 10**-2, 10**-3, 10**-4]\n",
        "    n_hiddens = [100, 150, 200, 250, 300, 350, 400]\n",
        "#     learning_rates = [ 10**-1]\n",
        "#     n_hiddens = [150, 200, 250]\n",
        "    sig = [0.1, 1, 10, 100]\n",
        "    print(\"hi\")\n",
        "#     train_loader = load_dataset()\n",
        "    print(\"2\")\n",
        "    best_ndcg = 0\n",
        "    for learning_rate in learning_rates:\n",
        "        for n_hidden in n_hiddens:\n",
        "            for sigma in sig:\n",
        "\n",
        "                print(\"\\nTesting learning_rate = {}, n_hidden = {} and sigma = {}\".format(learning_rate, n_hidden, sigma))\n",
        "                model = Model(data.num_features, n_hidden, learning_rate, sigma)\n",
        "\n",
        "                last_ndcg = 0\n",
        "                for epoch in range(epochs):\n",
        "\n",
        "                    model.ranknet.train()\n",
        "                    for qid in range(0, data.train.num_queries()):#\n",
        "                        if data.train.query_size(qid) < 2:#\n",
        "                            continue#\n",
        "                        s_i, e_i = data.train.query_range(qid)\n",
        "\n",
        "                        documentfeatures = torch.tensor(data.train.feature_matrix[s_i:e_i]).float()\n",
        "                        labels = torch.tensor(data.train.label_vector[s_i:e_i])\n",
        "    #                     if documentfeatures.shape[0] == 0:\n",
        "    #                         return torch.tensor([0.0], requires_grad= True)\n",
        "\n",
        "                        model = train_batch(documentfeatures, labels, model, sigma)  \n",
        "\n",
        "                                       \n",
        "                    scores = eval_model(model, data.validation)\n",
        "              \n",
        "                    ndcg = scores[\"ndcg\"][0]\n",
        "                    print(\"Epoch: {}, ndcg: {}\".format(epoch, ndcg))\n",
        "                            \n",
        "                    if ndcg < last_ndcg:\n",
        "                        break\n",
        "                    last_ndcg = ndcg\n",
        "                    if ndcg > best_ndcg:\n",
        "                        best_ndcg = ndcg\n",
        "                        best_params = {\"learning_rate\": learning_rate, \"n_hidden\": n_hidden, \"epoch\": epoch, \"sigma\": sigma}            \n",
        "                        print(\"Best parameters:\", best_params)\n",
        "    \n",
        "    return best_params\n",
        "\n",
        "# hyperparam_search()\n",
        "\n",
        "\n",
        "\n",
        "#### Loss functie 1tje kiezen voor validation en train.\n",
        "####  \n",
        "\n",
        "# {'learning_rate': 0.1, 'n_hidden': 100, 'epoch': 8}\n",
        "# {'learning_rate': 0.1, 'n_hidden': 250, 'epoch': 6}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "veVi9--TlXx6",
        "colab": {}
      },
      "source": [
        "\n",
        "def train_best(best_params):\n",
        "    epochs = best_params[\"epoch\"]\n",
        "    n_hidden = best_params[\"n_hidden\"]\n",
        "    learning_rate = best_params[\"learning_rate\"]\n",
        "    sigma = best_params[\"sigma\"]\n",
        "    \n",
        "    # load data\n",
        "#     data, train_loader = load_dataset()\n",
        "    model = Model(data.num_features, n_hidden, learning_rate, sigma)\n",
        "\n",
        "    losses, ndcgs = [], []\n",
        "    for epoch in range(epochs):\n",
        "        eval_count = 0\n",
        "        for qid in range(0, data.train.num_queries()):#\n",
        "            if data.train.query_size(qid) < 2:#\n",
        "                continue#\n",
        "            s_i, e_i = data.train.query_range(qid)\n",
        "            \n",
        "            documentfeatures = torch.tensor(data.train.feature_matrix[s_i:e_i]).float()\n",
        "            labels = torch.tensor(data.train.label_vector[s_i:e_i])\n",
        "            model = train_batch(documentfeatures, labels, model, sigma) \n",
        "            eval_count +=1\n",
        "            if eval_count % 2000 == 0:\n",
        "                scores = eval_model(model, data.validation)\n",
        "                ndcgs.append(scores[\"ndcg\"][0])\n",
        "        print(\"Epoch: {}, ndcg: {}\".format(epoch, scores[\"ndcg\"][0]))\n",
        "        \n",
        "    return ndcgs, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uy_km10Varfn",
        "outputId": "24a805a1-46ed-42d3-880b-ecdd0ae90eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# def train_best(best_params):\n",
        "#     epochs = best_params[\"epoch\"]\n",
        "#     n_hidden = best_params[\"n_hidden\"]\n",
        "#     learning_rate = best_params[\"learning_rate\"]\n",
        "    \n",
        "#     # load data\n",
        "#     data, train_loader = load_dataset()\n",
        "#     model = Model(data.num_features, n_hidden, learning_rate)\n",
        "\n",
        "#     losses, ndcgs = [], []\n",
        "#     for epoch in range(epochs):\n",
        "#         eval_count = 0\n",
        "#         for x_batch, y_batch in train_loader:\n",
        "#             model = train_batch(x_batch, y_batch, model)\n",
        "#             eval_count +=1\n",
        "#             if eval_count % 2000 == 0:\n",
        "#                 loss, scores = eval_model(model, data.validation)\n",
        "#                 losses.append(loss)\n",
        "#                 ndcgs.append(scores[\"ndcg\"][0])\n",
        "#         print(\"Epoch: {}, ndcg: {}\".format(epoch, scores[\"ndcg\"][0]))\n",
        "        \n",
        "#     return ndcgs, losses, model\n",
        "\n",
        "\n",
        "def get_distributions(model):\n",
        "    data = dataset.get_dataset().get_data_folds()[0]\n",
        "    data.read_data()\n",
        "    model.ranknet.eval()\n",
        "\n",
        "    val_x = torch.from_numpy(data.validation.feature_matrix).float()\n",
        "    test_x = torch.from_numpy(data.test.feature_matrix).float()\n",
        "           \n",
        "    val = model.ranknet(val_x).detach().cpu().numpy().squeeze()\n",
        "    test = model.ranknet(test_x).detach().cpu().numpy().squeeze()\n",
        "    actual = np.concatenate((data.train.label_vector, data.validation.label_vector, data.test.label_vector))\n",
        "    \n",
        "    distributions = {\n",
        "    \"val_mean\": np.mean(val),\n",
        "    \"val_std\": np.std(val),\n",
        "    \"test_mean\": np.mean(test),\n",
        "    \"test_std\": np.std(test),\n",
        "    \"actual_mean\": np.mean(actual), \n",
        "    \"actual_std\": np.std(actual),\n",
        "    }\n",
        "    \n",
        "    return distributions\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #determine best hyper parameters\n",
        "    best_params = hyperparam_search()\n",
        "    #train best model\n",
        "    ndcgs, model = train_best(best_params)\n",
        "    #plot ndcg and loss    \n",
        "    plot_ndcg_loss(ndcgs)\n",
        "    #get distributions of scores\n",
        "    distributions = get_distributions(model)\n",
        "    #performance on test set\n",
        "    data = dataset.get_dataset().get_data_folds()[0]\n",
        "    data.read_data()\n",
        "    scores = eval_model(model, data.test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hi\n",
            "2\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 100 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.715176462499171\n",
            "Best parameters: {'learning_rate': 0.1, 'n_hidden': 100, 'epoch': 0, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7196848404144485\n",
            "Best parameters: {'learning_rate': 0.1, 'n_hidden': 100, 'epoch': 1, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7171305902323315\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 100 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7163588993026664\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7185605736667938\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.714685539756695\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 100 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7173603128468151\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.717610058304086\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7174067616972266\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 100 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7182742641299418\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7170726612117999\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 150 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7170658293431952\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173980053532986\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7169136605251542\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 150 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7145430111347825\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7132454670753249\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 150 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7154281968732016\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.715187016279611\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 150 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7178191263829723\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7190947061993361\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7180312101422547\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 200 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7182943808376361\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7177002836986639\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 200 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.717347385856024\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.716727496673357\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 200 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7168052592370568\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7177729116891878\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7164404336436198\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 200 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7127744262830206\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173146780697827\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.71979857174995\n",
            "Best parameters: {'learning_rate': 0.1, 'n_hidden': 200, 'epoch': 2, 'sigma': 100}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7147904799709306\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 250 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7190783471323785\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7174208732922511\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 250 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7161363043621368\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.717867858377591\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7172778725920033\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 250 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7164615613698878\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7208447176511452\n",
            "Best parameters: {'learning_rate': 0.1, 'n_hidden': 250, 'epoch': 1, 'sigma': 10}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7157440687909234\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 250 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7178373242379306\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7193351429603287\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7177931218358145\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 300 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7188859504780418\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7175164277087404\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 300 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7182402569444032\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7194949190698313\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7188280003724838\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 300 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.715298785648053\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7171842099399652\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7162050116991755\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 300 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7167839328027542\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7143587210965033\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 350 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7212127529443966\n",
            "Best parameters: {'learning_rate': 0.1, 'n_hidden': 350, 'epoch': 0, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173134936857049\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 350 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.719981693333696\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7190992814257907\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 350 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7187602801550116\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7186911730120568\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 350 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7174635459928419\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7178840782604305\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7187369916126422\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7201319160343291\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.7169162865969998\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 400 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7196864121772297\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7128279559902772\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 400 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7196828674547864\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7182962422386145\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 400 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7171318154278361\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7197836609635059\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7206207660184097\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7202186435494267\n",
            "\n",
            "Testing learning_rate = 0.1, n_hidden = 400 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7204896465427238\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173197234463545\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 100 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7914776924645116\n",
            "Best parameters: {'learning_rate': 0.01, 'n_hidden': 100, 'epoch': 0, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173152357879576\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 100 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7172998579877312\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7168655308784142\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 100 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7187815220316074\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7178317617195303\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 100 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7181869507010671\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7153251167121897\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 150 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8025395960006343\n",
            "Best parameters: {'learning_rate': 0.01, 'n_hidden': 150, 'epoch': 0, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.800645183641916\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 150 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7205508387237559\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7188775778502864\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 150 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7224910752127347\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.716121653951267\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 150 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7191567116906682\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7172823550183035\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 200 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7176810745530152\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7160694131229202\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 200 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7152468070204692\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7180823446606911\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7169209811970195\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 200 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7179315355289226\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7157019407542364\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 200 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7176619540932183\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7194456019733163\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7163386922707031\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 250 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.716363009836352\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173196301044302\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7176885772770822\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7210047516136197\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.7204432246272126\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 250 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7183666517594826\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7172864835643077\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 250 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7157596670150965\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7150092145524378\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 250 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7195202623514655\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7196401402669352\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.720762154606338\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7207882604944474\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.718197447260216\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 300 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7200469501169481\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7175313904398816\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 300 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7157429169772004\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7171929996202033\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7196512814298186\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7149003285732751\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 300 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7183841028126827\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7177052920341996\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 300 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7160641599748181\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.719289813282171\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7172432163763657\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 350 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7194263241974205\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7182035573967821\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 350 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7191752887565029\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7161298093716361\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 350 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7167347205063688\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7193081090212944\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7178043892246746\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 350 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7144032606649651\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7180386544877295\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7161467462627035\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 400 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7969231270909098\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7182293352131471\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 400 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7179475375127775\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7126482879812153\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 400 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7161699544460134\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7198891198475514\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7209307301276352\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7182938606452207\n",
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 400 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7187704194714498\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7176779833947877\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 100 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8280411821000067\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 100, 'epoch': 0, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8298059743817506\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 100, 'epoch': 1, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8339326201877234\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 100, 'epoch': 2, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8356733268212005\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 100, 'epoch': 3, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8350330220511437\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 100 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.799899577620765\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7988436484595409\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 100 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7166793873551894\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7176229123402239\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7198711591145984\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7175641213203043\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 100 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.720161026090295\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.718325279544304\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 150 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8268166334944054\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8314696491163451\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.832917208965312\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.833771438524201\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8340656151758028\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.8349349815291525\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.8357551866809353\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 150, 'epoch': 6, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 7, ndcg: 0.8363048372427495\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 150, 'epoch': 7, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 8, ndcg: 0.8354961527057531\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 150 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7187064681837579\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7179990796499888\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 150 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7178720309467902\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7201251135596705\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7157074164143987\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 150 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7163073014434751\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7165450361721588\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7166345804374882\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7175343747181521\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.7189579717105934\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.7172335015645233\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 200 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8277469053427029\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8295671665500542\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8337479575061065\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8357841351527551\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8354196128161332\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 200 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7907556421823522\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7939244554339746\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8100351030213164\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7944572958690135\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 200 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7187076000457061\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173941184212799\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 200 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7195453799609549\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7167527002503548\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 250 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8275487218110942\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8310152428912368\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8312072319206832\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8325232680331983\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8344204940870084\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.8360106359964522\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.835552923976854\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 250 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8084696324736246\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7995428754290502\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 250 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7186923197666826\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.71598040070525\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 250 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7161734030757567\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.717175186736972\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7162808123018296\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 300 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.827230109645882\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8298682715690205\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.832469514257297\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8344734306264374\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8371357047506574\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 300, 'epoch': 4, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.8388561099959692\n",
            "Best parameters: {'learning_rate': 0.001, 'n_hidden': 300, 'epoch': 5, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.8376435524407471\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 300 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7214136381711104\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7179205775488753\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 300 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7164436657534551\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7178301443826732\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7139504173385166\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 300 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7170277665589782\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7181536209734283\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7183500585669209\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7171069893060454\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 350 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8278729683106073\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.831184788333402\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8334377011205748\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8337386887449798\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8376534119909657\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.8377688232482497\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.8388015536802793\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 7, ndcg: 0.838105738753058\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 350 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7175008189067323\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7178416281300763\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7182067112037264\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7171779138010208\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 350 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7178652473122894\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7173100223618174\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 350 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7187540538419791\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7195856502961304\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7190865500929902\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 400 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8280939394417594\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8315893891196642\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8354092235556352\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8352395908818132\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 400 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7160327641116123\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7140735276300162\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 400 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7158395627812933\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7180854713278852\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.7186953665594998\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.7216539495631015\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.7174919908485967\n",
            "\n",
            "Testing learning_rate = 0.001, n_hidden = 400 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7191939140469172\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.717519706583069\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 100 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8295798358641354\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.832177565938138\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8336735664962297\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.834652222224196\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8355761132519174\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.8368563183889982\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.8376741471953432\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 7, ndcg: 0.8380544073310633\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 8, ndcg: 0.8390020619515424\n",
            "Best parameters: {'learning_rate': 0.0001, 'n_hidden': 100, 'epoch': 8, 'sigma': 0.1}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 9, ndcg: 0.8400304444074177\n",
            "Best parameters: {'learning_rate': 0.0001, 'n_hidden': 100, 'epoch': 9, 'sigma': 0.1}\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 100 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8286421257649336\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.829906124710701\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8344069633190563\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8358061452998844\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8355950729403493\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 100 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7977766222848776\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7957377493424692\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 100 and sigma = 100\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7198308150327194\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.7172625420943648\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 150 and sigma = 0.1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8296968421543988\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8317941285456887\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.8341753452977076\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8344259846385251\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8364595413790283\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.837171903454962\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.8378073532085609\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 7, ndcg: 0.8381928507682335\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 8, ndcg: 0.8388293704797236\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 9, ndcg: 0.8394282926032475\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 150 and sigma = 1\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8282093102910746\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.830541316800803\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 2, ndcg: 0.83262280000951\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 3, ndcg: 0.8333156666705016\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 4, ndcg: 0.8333593723117725\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 5, ndcg: 0.8346418768560426\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 6, ndcg: 0.8336310681434709\n",
            "\n",
            "Testing learning_rate = 0.0001, n_hidden = 150 and sigma = 10\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.7184531954204973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e3b6fb49ea1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#determine best hyper parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m#train best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mndcgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-577cb69dd735>\u001b[0m in \u001b[0;36mhyperparam_search\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m#                         return torch.tensor([0.0], requires_grad= True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocumentfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-577cb69dd735>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(documentfeatures, labels, model, sig)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwiseloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PYr5Lqm6ausr",
        "outputId": "ace81006-b33e-45cc-a6cd-133bdefe67f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "\n",
        "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#torch.manual_seed(0)\n",
        "\n",
        "class RankNetSU(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden):\n",
        "        super(RankNetSU, self).__init__()\n",
        "        self.hidden = torch.nn.Linear(n_feature, n_hidden)\n",
        "        self.output = torch.nn.Linear(n_hidden, 1)      \n",
        "        \n",
        "    def forward(self, x1):\n",
        "        x = torch.nn.functional.relu(self.hidden(x1))\n",
        "        x = self.output(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "class Model():\n",
        "    def __init__(self, n_feature, n_hidden, learning_rate, sigma):\n",
        "        self.ranknet = RankNetSU(n_feature, n_hidden)\n",
        "        #.to(device)\n",
        "        self.optimizer = torch.optim.SGD(self.ranknet.parameters(), lr=learning_rate)\n",
        "\n",
        "def eval_model(model, data_fold):\n",
        "    #with torch.no_grad():\n",
        "        x = torch.from_numpy(data_fold.feature_matrix).float()\n",
        "        y = data_fold.label_vector\n",
        "        model.ranknet.eval()\n",
        "               \n",
        "        output = model.ranknet(x)\n",
        "        output = output.detach().cpu().numpy().squeeze()\n",
        "        \n",
        "        scores = evl.evaluate(data_fold, np.asarray(output))  \n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "\n",
        "    train_x = torch.from_numpy(data.train.feature_matrix).float()\n",
        "    train_y = torch.from_numpy(data.train.label_vector).float()\n",
        "\n",
        "    train_set = TensorDataset(train_x, train_y)\n",
        "    train_loader = DataLoader(dataset=train_set, batch_size=32, shuffle=True)\n",
        "\n",
        "    return train_loader\n",
        "       \n",
        "\n",
        "def plot_ndcg_loss(losses, ndcgs):\n",
        "    x = np.arange(len(losses))\n",
        "    fig, ax = plt.subplots()\n",
        "    \n",
        "    ax.plot(x, losses, label='Loss')\n",
        "    ax.plot(x, ndcgs, label='NDCG')\n",
        "    ax.set_xlabel(\"Batch % 2000\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_title(\"LambdaRank\")\n",
        "    legend = ax.legend(loc='upper center')\n",
        "    \n",
        "    plt.show()\n",
        "    plt.savefig('LambdaRank_plot.png')\n",
        "\n",
        "    \n",
        "def train_batch(documentfeatures, labels, model, sig):\n",
        "#     model.ranknet.train()\n",
        "    for epoch in range(1):\n",
        "#         for qid in range(0, train_data.num_queries()):\n",
        "#             if train_data.query_size(qid) < 2:\n",
        "#                 continue\n",
        "            model.optimizer.zero_grad()\n",
        "\n",
        "            output = model.ranknet(documentfeatures)\n",
        "            \n",
        "            loss = pairwiseloss(output, labels, sig)\n",
        "            \n",
        "            # AttributeError: 'Tensor' object has no attribute 'forward'\n",
        "            \n",
        "            loss.sum().backward()\n",
        "            \n",
        "            model.optimizer.step()\n",
        "\n",
        "    return model\n",
        "    \n",
        "def pairwiseloss(predictedvals, values, sig):\n",
        "    \n",
        "    predictedvals = predictedvals.squeeze()\n",
        "\n",
        "    if values.shape[0] == 1:\n",
        "        return torch.tensor((predictedvals - values)**2, requires_grad= True)\n",
        "    pairs = list(itertools.combinations(range(predictedvals.shape[0]), 2))\n",
        "    val1, val2 = [x[0] for x in pairs], [x[1] for x in pairs]\n",
        "    #todevice\n",
        "    # pred1 = predictedvals[val1]\n",
        "    # pred2 = predictedvals[val2]\n",
        "    \n",
        "    # true1 = values[val1]\n",
        "    # true2 = values[val2]\n",
        "    # #.todevice\n",
        "    # s1 = (true1 > true2).type(torch.ByteTensor)\n",
        "    # s2 = (true1 < true2).type(torch.ByteTensor)\n",
        "    \n",
        "    # S =  s1 - s2\n",
        "    # S = torch.tensor(S)\n",
        "   \n",
        "    S = torch.sign(values[val1] - values[val2])\n",
        "    s = predictedvals[val1] - predictedvals[val2] \n",
        "\n",
        "    sigma = sig\n",
        "    lambda_ij = sig*(torch.FloatTensor([0.5])*(torch.FloatTensor([1])-S)-(torch.FloatTensor([1])/(torch.FloatTensor([1])+torch.exp(s*sig))))\n",
        "#     print(lambda_ij.shape)\n",
        "#     lambda_ij = torch.sigmoid(torch.FloatTensor([0.5])*(torch.FloatTensor([1])-S)torch.log(torch.FloatTensor([1])+torch.exp(-((s_i-s_j).sigmoid().view(s_i.size(0)))))\n",
        "#     print(predictedvals.shape)\n",
        "    lambda_i = np.zeros(len(set(val1))+1)\n",
        "    n=0\n",
        "    for i in val1:\n",
        "        lambda_i[i]+= lambda_ij[n]\n",
        "        n += 1\n",
        "    m = 0\n",
        "    for j in val2:\n",
        "        lambda_i[j]-= lambda_ij[m] \n",
        "        m += 1\n",
        "    lambda_i = torch.tensor(lambda_i, requires_grad=True)\n",
        "\n",
        "    return predictedvals * lambda_i.detach()\n",
        "\n",
        "\n",
        "def hyperparam_search():\n",
        "    # hyper-parameters\n",
        "    # epochs = 10\n",
        "    # learning_rates = [10**-1, 10**-2, 10**-3, 10**-4]\n",
        "    # n_hiddens = [100, 150, 200, 250, 300, 350, 400]\n",
        "    # sigma = [0.1, 1, 10, 60, 100]\n",
        "    epochs = 10\n",
        "    learning_rates = [10**-2, 10**-3, 10**-1]\n",
        "    n_hiddens = [150, 200, 250, 300, 350]\n",
        "    sigmas = [10**-2, 10**-3]\n",
        "\n",
        "    best_ndcg = 0\n",
        "    for learning_rate in learning_rates:\n",
        "        for n_hidden in n_hiddens:\n",
        "            for sig in sigmas:\n",
        "        \n",
        "                print(\"\\nTesting learning_rate = {}, n_hidden = {} and sigma = {}\".format(learning_rate, n_hidden, sig))\n",
        "                model = Model(data.num_features, n_hidden, learning_rate, sig)\n",
        "\n",
        "                last_ndcg = 0\n",
        "                for epoch in range(epochs):\n",
        "\n",
        "                    model.ranknet.train()\n",
        "                    for qid in range(0, data.train.num_queries()):#\n",
        "                        if data.train.query_size(qid) < 2:#\n",
        "                            continue#\n",
        "                        s_i, e_i = data.train.query_range(qid)\n",
        "\n",
        "                        documentfeatures = torch.tensor(data.train.feature_matrix[s_i:e_i]).float()\n",
        "                        labels = torch.tensor(data.train.label_vector[s_i:e_i])\n",
        "\n",
        "                        model = train_batch(documentfeatures, labels, model, sig)  \n",
        "\n",
        "\n",
        "                    scores = eval_model(model, data.validation)\n",
        "\n",
        "                    ndcg = scores[\"ndcg\"][0]\n",
        "                    print(\"Epoch: {}, ndcg: {}\".format(epoch, ndcg))\n",
        "\n",
        "                    if ndcg < last_ndcg:\n",
        "                        break\n",
        "                    last_ndcg = ndcg\n",
        "                    if ndcg > best_ndcg:\n",
        "                        best_ndcg = ndcg\n",
        "                        best_params = {\"learning_rate\": learning_rate, \"n_hidden\": n_hidden, \"epoch\": epoch, \"sigma\": sig}            \n",
        "                        print(\"Best parameters:\", best_params)\n",
        "    \n",
        "    return best_params\n",
        "\n",
        "\n",
        "def train_best(best_params):\n",
        "    epochs = best_params[\"epoch\"]\n",
        "    n_hidden = best_params[\"n_hidden\"]\n",
        "    learning_rate = best_params[\"learning_rate\"]\n",
        "    sigma = best_params[\"sigma\"]\n",
        "    \n",
        "    model = Model(data.num_features, n_hidden, learning_rate, sigma)\n",
        "\n",
        "    losses, ndcgs = [], []\n",
        "    for epoch in range(epochs):\n",
        "        eval_count = 0\n",
        "        for qid in range(0, data.train.num_queries()):#\n",
        "            if data.train.query_size(qid) < 2:#\n",
        "                continue#\n",
        "            s_i, e_i = data.train.query_range(qid)\n",
        "            \n",
        "            documentfeatures = torch.tensor(data.train.feature_matrix[s_i:e_i]).float()\n",
        "            labels = torch.tensor(data.train.label_vector[s_i:e_i])\n",
        "            model = train_batch(documentfeatures, labels, model, sigma) \n",
        "            eval_count +=1\n",
        "            if eval_count % 2000 == 0:\n",
        "                scores = eval_model(model, data.validation)\n",
        "                ndcgs.append(scores[\"ndcg\"][0])\n",
        "        print(\"Epoch: {}, ndcg: {}\".format(epoch, scores[\"ndcg\"][0]))\n",
        "        \n",
        "    return ndcgs, model\n",
        "\n",
        "\n",
        "def get_distributions(model):\n",
        "    data = dataset.get_dataset().get_data_folds()[0]\n",
        "    data.read_data()\n",
        "    model.ranknet.eval()\n",
        "\n",
        "    val_x = torch.from_numpy(data.validation.feature_matrix).float()\n",
        "    test_x = torch.from_numpy(data.test.feature_matrix).float()\n",
        "           \n",
        "    val = model.ranknet(val_x).detach().cpu().numpy().squeeze()\n",
        "    test = model.ranknet(test_x).detach().cpu().numpy().squeeze()\n",
        "    actual = np.concatenate((data.train.label_vector, data.validation.label_vector, data.test.label_vector))\n",
        "    \n",
        "    distributions = {\n",
        "    \"val_mean\": np.mean(val),\n",
        "    \"val_std\": np.std(val),\n",
        "    \"test_mean\": np.mean(test),\n",
        "    \"test_std\": np.std(test),\n",
        "    \"actual_mean\": np.mean(actual), \n",
        "    \"actual_std\": np.std(actual),\n",
        "    }\n",
        "    \n",
        "    return distributions\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    #determine best hyper parameters\n",
        "    best_params = hyperparam_search()\n",
        "    #train best model\n",
        "    ndcgs, model = train_best(best_params)\n",
        "    #plot ndcg and loss    \n",
        "    plot_ndcg_loss(ndcgs)\n",
        "    #get distributions of scores\n",
        "    distributions = get_distributions(model)\n",
        "    #performance on test set\n",
        "    data = dataset.get_dataset().get_data_folds()[0]\n",
        "    data.read_data()\n",
        "    scores = eval_model(model, data.test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Testing learning_rate = 0.01, n_hidden = 150 and sigma = 0.01\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 0, ndcg: 0.8272611090299362\n",
            "Best parameters: {'learning_rate': 0.01, 'n_hidden': 150, 'epoch': 0, 'sigma': 0.01}\n",
            "\"metric\": \"mean\" (\"standard deviation\")\n",
            "Epoch: 1, ndcg: 0.8294855575327502\n",
            "Best parameters: {'learning_rate': 0.01, 'n_hidden': 150, 'epoch': 1, 'sigma': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6wv0Oqd4akqP",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nNNyCVQ5akqa",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrjIBv_tGUAn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-VcTZwpGTbX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWHKj8cQGTJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "c4jxUhn8akqn",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}